{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iafPdtuncbq7"
   },
   "source": [
    "<h1><center>MNIST classification using Numpy<center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## by: Jos√© Lucas Barretto and Lucas Celinga Agrizzi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I4VrCB5La5rD"
   },
   "source": [
    "## Importing Numpy and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OlKZ3Hnas7B4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucasagrizzi/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lucasagrizzi/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lucasagrizzi/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lucasagrizzi/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lucasagrizzi/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lucasagrizzi/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/lucasagrizzi/anaconda3/envs/py37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lucasagrizzi/anaconda3/envs/py37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lucasagrizzi/anaconda3/envs/py37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lucasagrizzi/anaconda3/envs/py37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lucasagrizzi/anaconda3/envs/py37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lucasagrizzi/anaconda3/envs/py37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "# print(\"Using tensorflow version \" + str(tf.__version__))\n",
    "# print(\"Using keras version \" + str(keras.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_QLz9_jbRZq"
   },
   "source": [
    "## Loading and preparing the MNIST dataset\n",
    "Load the MNIST dataset made available by keras.datasets. Check the size of the training and testing sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "gG83hGyVmijn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data format - X: (60000, 28, 28) , y: (60000,)\n",
      "test data format - X: (10000, 28, 28) , y: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# The MNSIT dataset is ready to be imported from Keras into RAM\n",
    "# Warning: you cannot do that for larger databases (e.g., ImageNet)\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "print('train data format - X:', train_images.shape, ', y:', train_labels.shape)\n",
    "print('test data format - X:', test_images.shape, ', y:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gRPbU_Z4U6Ac"
   },
   "source": [
    "The MNIST database contains 60,000 training images and 10,000 testing images.\n",
    "Using the pyplot package, visualize the first sample of the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5VAu7oW0Zu4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let us visualize the first training sample using the Matplotlib library\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.title('First Training Image - Label: ' + str(train_labels[0]), pad=15)\n",
    "plt.imshow(train_images[0], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s7YsRekMVDg-"
   },
   "source": [
    "The database contains images of handwritten digits. Hence, they belong to one of 10 categories, depending on the digit they represent. \n",
    "Reminder: in order to do multi-class classification, we use the softmax function, which outputs a multinomial probability distribution. That means that the output to our model will be a vector of size $10$, containing probabilities (meaning that the elements of the vector will be positive sum to $1$).\n",
    "For easy computation, we want to true labels to be represented with the same format: that is what we call **one-hot encoding**. For example, if an image $\\mathbf{x}$ represents the digit $5$, we have the corresponding one_hot label (careful, $0$ will be the first digit): \n",
    "$$ \\mathbf{y} = [0, 0, 0, 0, 0, 1, 0, 0, 0, 0] $$\n",
    "Here, you need to turn train and test labels to one-hot encoding using the following function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lQbkllF8mnaf"
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "num_categories = 10\n",
    "\n",
    "train_labels = to_categorical(train_labels, num_categories)\n",
    "test_labels = to_categorical(test_labels, num_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0jv29YLtVO3q"
   },
   "source": [
    "Images are black and white, with size $28 \\times 28$. We will work with them using a simple linear classification model, meaning that we will have them as vectors of size $(784)$.\n",
    "You should then transform the images to the size $(784)$ using the numpy function ```reshape```.\n",
    "\n",
    "Then, after casting the pixels to floats, normalize the images so that they have zero-mean and unitary deviation. Be careful to your methodology: while you have access to training data, you may not have access to testing data, and must avoid using any statistic on the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ptTRSDo5nJyZ"
   },
   "outputs": [],
   "source": [
    "# Reshape to proper images with 1 color channel according to backend scheme\n",
    "train_images = train_images.reshape(len(train_images), -1)\n",
    "test_images = test_images.reshape(len(test_images), -1)\n",
    "\n",
    "# Cast pixels from uint8 to float32\n",
    "train_images = train_images.astype('float32')\n",
    "test_images = test_images.astype('float32')\n",
    "\n",
    "# Now let us normalize the images so that they have zero mean and standard deviation\n",
    "# Hint: are real testing data statistics known at training time ? Answer: NO\n",
    "\n",
    "eps = 1e-7\n",
    "\n",
    "# calculate statistics from training data\n",
    "mean = np.mean(train_images)\n",
    "std = np.std(train_images) + eps # sum eps to avoid division by zero\n",
    "\n",
    "# normalize using training data statistics - avoids data leakage\n",
    "normal_train_images = (train_images - mean)/std\n",
    "normal_test_images = (test_images - mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Numpy\n",
    "\n",
    "Look at this [cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf) for some basic information on how to use numpy.\n",
    "\n",
    "## Defining the model \n",
    "\n",
    "We will here create a simple, linear classification model. We will take each pixel in the image as an input feature (making the size of the input to be $784$) and transform these features with a weight matrix $\\mathbf{W}$ and a bias vector $\\mathbf{b}$. Since there is $10$ possible classes, we want to obtain $10$ scores. Then, \n",
    "$$ \\mathbf{W} \\in \\mathbb{R}^{784 \\times 10} $$\n",
    "$$ \\mathbf{b} \\in \\mathbb{R}^{10} $$\n",
    "\n",
    "and our scores are obtained with:\n",
    "$$ \\mathbf{z} = \\mathbf{W}^{T} \\mathbf{x} +  \\mathbf{b} $$\n",
    "\n",
    "where $\\mathbf{x} \\in \\mathbb{R}^{784}$ is the input vector representing an image.\n",
    "We note $\\mathbf{y} \\in \\mathbb{R}^{10}$ as the target one_hot vector. \n",
    "\n",
    "Here, you fist need to initialize $\\mathbf{W}$ and $\\mathbf{b}$ using ```np.random.normal``` and ```np.zeros```, then compute $\\mathbf{z}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid implementing a complicated gradient back-propagation,\n",
    "# we will try a very simple architecture with one layer \n",
    "def initLayer(n_input,n_output):\n",
    "    \"\"\"\n",
    "    Initialize the weights, return the number of parameters\n",
    "    Inputs: n_input: the number of input units - int\n",
    "          : n_output: the number of output units - int\n",
    "    Outputs: W: a matrix of weights for the layer - numpy ndarray\n",
    "           : b: a vector bias for the layer - numpy ndarray\n",
    "           : nb_params: the number of parameters  - int\n",
    "    \"\"\"\n",
    "    \n",
    "    W = np.random.normal(size=(n_input,n_output))\n",
    "    b = np.zeros(n_output)\n",
    "    b.reshape(n_output)\n",
    "    \n",
    "    nb_params = n_input*n_output + n_output\n",
    "    \n",
    "    return W, b, nb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_training = train_images.shape[0] \n",
    "n_feature = train_images.shape[1]\n",
    "n_labels = 10\n",
    "W, b, nb_params = initLayer(n_feature, n_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W shape: (784, 10)\n",
      "b shape: (10,)\n",
      "train images shape: (60000, 784)\n"
     ]
    }
   ],
   "source": [
    "# see the shapes\n",
    "print('W shape:', W.shape)\n",
    "print('b shape:', b.shape)\n",
    "print('train images shape:', normal_train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(W, b, X):\n",
    "    \"\"\"\n",
    "    Perform the forward propagation\n",
    "    Inputs: W: the weights - numpy ndarray\n",
    "          : b: the bias - numpy ndarray\n",
    "          : X: the batch - numpy ndarray\n",
    "    Outputs: z: outputs - numpy ndarray\n",
    "    \"\"\"\n",
    "    z = X @ W + b # CODE HERE\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z shape: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "z = forward(W, b, train_images)\n",
    "print('z shape:', z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the output \n",
    "\n",
    "To obtain classification probabilities, we use the softmax function:\n",
    "$$ \\mathbf{o} = softmax(\\mathbf{z}) \\text{         with          } o_i = \\frac{\\exp(z_i)}{\\sum_{j=0}^{9} \\exp(z_j)} $$\n",
    "\n",
    "The usual difficulty with the softmax function is the possibility of overflow when the scores $z_i$ are already large. Since a softmax is not affected by a shift affecting the whole vector $\\mathbf{z}$:\n",
    "$$ \\frac{\\exp(z_i - c)}{\\sum_{j=0}^{9} \\exp(z_j - c)} =  \\frac{\\exp(c) \\exp(z_i)}{\\exp(c) \\sum_{j=0}^{9} \\exp(z_j)} = \\frac{\\exp(z_i)}{\\sum_{j=0}^{9} \\exp(z_j)}$$\n",
    "what trick can we use to ensure we will not encounter any overflow ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    \"\"\"\n",
    "    Perform the softmax transformation to the pre-activation values\n",
    "    Inputs: z: the pre-activation values - numpy ndarray\n",
    "    Outputs: out: the activation values - numpy ndarray\n",
    "    \"\"\"\n",
    "    c = z.max()\n",
    "    exp_z = np.exp(z-c)\n",
    "    out = exp_z/np.sum(exp_z)# CODE HERE\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making updates\n",
    "\n",
    "We define a learning rate $\\eta$. The goal is to be able to apply updates:\n",
    "$$ \\mathbf{W}^{t+1} = \\mathbf{W}^{t} - \\nabla_{\\mathbf{W}} l_{ML} $$\n",
    "\n",
    "In order to do this, we will compute this gradient (and the bias) in the function ```update```. In the next function ```updateParams```, we will actually apply the update with regularization. \n",
    "\n",
    "Reminder: the gradient $\\nabla_{\\mathbf{W}} l_{ML}$ is the matrix containing the partial derivatives \n",
    "$$ \\left[\\frac{\\delta l_{ML}}{\\delta W_{ij}}\\right]_{i=1..784, j=1..10} $$\n",
    "\n",
    "\n",
    "Coordinate by coordinate, we obtain the following update: \n",
    "$$ W_{ij}^{t+1} = W_{ij}^{t} - \\frac{\\delta l_{ML}}{\\delta W_{ij}} $$\n",
    "\n",
    "Via the chain rule, we obtain, for an input feature $i \\in [0, 783]$ and a output class $j \\in [0, 9]$: $$\\frac{\\delta l_{ML}}{\\delta W_{ij}} = \\frac{\\delta l_{ML}}{\\delta z_{j}} \\frac{\\delta z_j}{\\delta W_{ij}}$$ \n",
    "\n",
    "It's easy to compute that $\\frac{\\delta z_j}{\\delta W_{ij}} = x_i$\n",
    "\n",
    "We compute the softmax derivative, to obtain:\n",
    "$$ \\nabla_{\\mathbf{z}} l_{ML} = \\mathbf{o} - \\mathbf{y} $$\n",
    "\n",
    "Hence, $\\frac{\\delta l_{ML}}{\\delta z_{j}} = o_j - y_j$ and we obtain that $$\\frac{\\delta l_{ML}}{\\delta W_{ij}} = (o_j - y_j) x_i$$\n",
    "\n",
    "This can easily be written as a scalar product, and a similar computation (even easier, actually) can be done for $\\mathbf{b}$. Noting $\\nabla_{\\mathbf{z}} l_{ML} = \\mathbf{o} - \\mathbf{y}$ as ```grad``` in the following function, compute the gradients $\\nabla_{\\mathbf{W}} l_{ML}$ and $\\nabla_{\\mathbf{b}} l_{ML}$ in order to call the function ```updateParams```.\n",
    "\n",
    "Note: the regularizer and the weight_decay $\\lambda$ are used in ```updateParams```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(eta, W, b, grad, X, regularizer, weight_decay):\n",
    "    \"\"\"\n",
    "    Perform the update of the parameters\n",
    "    Inputs: eta: the step-size of the gradient descent - float \n",
    "          : W: the weights - ndarray\n",
    "          : b: the bias -  ndarray\n",
    "          : grad: the gradient of the activations w.r.t. to the loss -  list of ndarray\n",
    "          : X: the data -  ndarray\n",
    "          : regularizer: 'L2' or None - the regularizer to be used in updateParams\n",
    "          : weight_decay: the weight decay to be used in updateParams - float\n",
    "    Outputs: W: the weights updated -  ndarray\n",
    "           : b: the bias updated -  ndarray\n",
    "    \"\"\"  \n",
    "   \n",
    "    grad_w = X.reshape((-1,1)) @ grad.reshape((-1,1)).T # CODE HERE\n",
    "    grad_b = grad # CODE HERE\n",
    "        \n",
    "    W = updateParams(W, grad_w, eta, regularizer, weight_decay)\n",
    "    b = updateParams(b, grad_b, eta, regularizer, weight_decay)\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The update rule is affected by regularization. We implement two cases: No regularization, or L2 regularization. Use the two possible update rules to implement the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateParams(param, grad_param, eta, regularizer=None, weight_decay=0.):\n",
    "    \"\"\"\n",
    "    Perform the update of the parameters\n",
    "    Inputs: param: the network parameters - ndarray\n",
    "          : grad_param: the updates of the parameters - ndarray\n",
    "          : eta: the step-size of the gradient descent - float\n",
    "          : weight_decay: the weight-decay - float\n",
    "    Outputs: the parameters updated - ndarray\n",
    "    \"\"\"\n",
    "    if regularizer==None:\n",
    "        return param - eta*grad_param # CODE HERE\n",
    "    elif regularizer=='L2':\n",
    "        return (1-2*weight_decay)*param - eta*grad_param # CODE HERE\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Accuracy\n",
    "\n",
    "Here, we simply use the model to predict the class (by taking the argmax of the output !) for every example in ```X```, and count the number of times the model is right, to output the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAcc(W, b, X, labels):\n",
    "    \"\"\"\n",
    "    Compute the loss value of the current network on the full batch\n",
    "    Inputs: act_func: the activation function - function\n",
    "          : W: the weights - list of ndarray\n",
    "          : B: the bias - list of ndarray\n",
    "          : X: the batch - ndarray\n",
    "          : labels: the labels corresponding to the batch\n",
    "    Outputs: loss: the negative log-likelihood - float\n",
    "           : accuracy: the ratio of examples that are well-classified - float\n",
    "    \"\"\" \n",
    "\n",
    "    ### Forward propagation\n",
    "    z = forward(W, b, X)# CODE HERE\n",
    "\n",
    "    ### Compute the softmax and the prediction\n",
    "    out = softmax(z)# CODE HERE\n",
    "\n",
    "    pred = np.argmax(out, axis=1)# CODE HERE\n",
    "    ans = np.argmax(labels, axis=1)\n",
    "\n",
    "    ### Compute the accuracy\n",
    "    accuracy = np.mean(pred==ans) # CODE HERE\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing training\n",
    "\n",
    "The following hyperparameters are given. Next, we can assemble all the function previously defined to implement a training loop. We will train the classifier on **one epoch**, meaning that the model will see each trainin example once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization\n",
    "eta = 0.01\n",
    "regularizer = 'L2'\n",
    "weight_decay = 0.0001\n",
    "\n",
    "# Training\n",
    "log_interval = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy table over iterations:\n",
      "\n",
      "iteration\ttrain_acc\tvalid_acc\tlearning_rate\n",
      "0\t\t0.0906\t\t0.083\t\t0.01\n",
      "3000\t\t0.789\t\t0.7914\t\t0.01\n",
      "6000\t\t0.8256\t\t0.8347\t\t0.01\n",
      "9000\t\t0.8126\t\t0.8097\t\t0.01\n",
      "12000\t\t0.8300\t\t0.8324\t\t0.01\n",
      "15000\t\t0.8222\t\t0.8189\t\t0.01\n",
      "18000\t\t0.8379\t\t0.8421\t\t0.01\n",
      "21000\t\t0.7855\t\t0.7954\t\t0.01\n",
      "24000\t\t0.8248\t\t0.8338\t\t0.01\n",
      "27000\t\t0.8321\t\t0.8382\t\t0.01\n",
      "30000\t\t0.7964\t\t0.7985\t\t0.01\n",
      "33000\t\t0.7995\t\t0.8045\t\t0.01\n",
      "36000\t\t0.7485\t\t0.7532\t\t0.01\n",
      "39000\t\t0.8302\t\t0.8319\t\t0.01\n",
      "42000\t\t0.8010\t\t0.8021\t\t0.01\n",
      "45000\t\t0.8520\t\t0.8546\t\t0.01\n",
      "48000\t\t0.8350\t\t0.8393\t\t0.01\n",
      "51000\t\t0.838\t\t0.8467\t\t0.01\n",
      "54000\t\t0.7605\t\t0.7683\t\t0.01\n",
      "57000\t\t0.8082\t\t0.8202\t\t0.01\n",
      "\n",
      " Final result:\n",
      "\t\t0.7576\t\t0.756\t\t0.01\n",
      "\n",
      " Best result:\n",
      "45000\t\t0.8520\t\t0.8546\t\t0.01\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy table over iterations:\\n')\n",
    "print('iteration\\ttrain_acc\\tvalid_acc\\tlearning_rate')\n",
    "# Data structures for plotting\n",
    "g_train_acc=[]\n",
    "g_valid_acc=[]\n",
    "\n",
    "# init weights\n",
    "W, b, nb_params = initLayer(n_feature, n_labels)\n",
    "\n",
    "#######################\n",
    "### Learning process ##\n",
    "#######################\n",
    "for j in range(n_training):\n",
    "    \n",
    "    ### Getting the example\n",
    "    X = normal_train_images[j].reshape((1,-1))  \n",
    "    y = train_labels[j].reshape((1,-1)) # CODE HERE\n",
    "\n",
    "    ### Forward propagation\n",
    "    z = forward(W, b, X) # CODE HERE\n",
    "    \n",
    "    ### Compute the softmax\n",
    "    out = softmax(z)# CODE HERE\n",
    "\n",
    "    ### Compute the gradient at the top layer\n",
    "    derror = out - y # This is o - y \n",
    "\n",
    "    ### Update the parameters\n",
    "    W, b = update(eta, W, b, derror.reshape(-1,), X, regularizer, weight_decay)# CODE HERE\n",
    "\n",
    "    if j % log_interval == 0:\n",
    "        \n",
    "        ### Every log_interval examples, look at the training accuracy\n",
    "        train_accuracy = computeAcc(W, b, normal_train_images, train_labels) \n",
    "\n",
    "        ### And the testing accuracy\n",
    "        test_accuracy = computeAcc(W, b, normal_test_images, test_labels) \n",
    "\n",
    "        g_train_acc.append(train_accuracy)\n",
    "        g_valid_acc.append(test_accuracy)\n",
    "        result_line = str(int(j)) + \"\\t\\t\" + str(train_accuracy)[:6] + \"\\t\\t\" + str(test_accuracy)[:6] + \"\\t\\t\" + str(eta)\n",
    "        print(result_line)\n",
    "\n",
    "# calcule the acc for the last point\n",
    "train_accuracy = computeAcc(W, b, normal_train_images, train_labels)\n",
    "valid_accuracy = computeAcc(W, b, normal_test_images, test_labels)\n",
    "\n",
    "g_train_acc.append(train_accuracy)\n",
    "g_valid_acc.append(valid_accuracy)\n",
    "result_line = \"Final result:\" + \"\\n\\t\\t\" + str(train_accuracy)[:6] + \"\\t\\t\" + str(valid_accuracy)[:6] + \"\\t\\t\" + str(eta)\n",
    "print('\\n',result_line) \n",
    "\n",
    "# Find best training fit \n",
    "index_max = np.argmax(g_valid_acc)\n",
    "best_line = \"Best result:\" + \"\\n\" + str(index_max*log_interval) + \"\\t\\t\" + str(g_train_acc[index_max])[:6] + \"\\t\\t\" + str(g_valid_acc[index_max])[:6] + \"\\t\\t\" + str(eta)\n",
    "print('\\n',best_line) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the accuracy as a performance measure\n",
    "x = np.arange(len(g_train_acc))*log_interval\n",
    "\n",
    "plt.figure(figsize=(9,4))\n",
    "plt.plot(x, g_train_acc, '-o', label='train')\n",
    "plt.plot(x, g_valid_acc, '--o', label='validation')\n",
    "\n",
    "plt.title('Performance graph')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What can you say about the performance of this simple linear classifier ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier can achieve for some points, more than 80% of accuracy for the parameters recommended. As we can not affirm that the function is convex, we can find some local minimums. We can notice that the function is not convex because the stochastic gradient descent does not make the accuracy arrive in a stable point. Because of this, we can notice that the best model, considering only the test set as the metric of accuracy, could not be the last point.\n",
    "\n",
    "In the project, we achieve the final accuracy around 75%, but the best accuracy of the model was around 85%. Furthermore, as the two accuracies run over the same sample, we see that the model classifies better for a specific point during the learning.\n",
    "\n",
    "\n",
    "To better adapt to this problem, we usually try to avoid local minimum optimizing the learning rate and weight_decay hyperparameters or going to more complex architectures."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TP4_1_empty.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (py37)",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
